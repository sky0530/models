runtime:
  distribution_strategy: 'mirrored'
  mixed_precision_dtype: 'float16'
  loss_scale: 'dynamic'
task:
  model:
    num_classes: 1000
    input_size: [224, 224, 3]
    backbone:
      type: 'resnet'
      resnet:
        model_id: 50
    kernel_initializer: 'he_normal'
  losses:
    l2_weight_decay: 0.0001
    one_hot: true
    label_smoothing: 0.1
  train_data:
    input_path: '/data/imagenet/tf_record/train/train*'
    is_training: true
    global_batch_size: 4096
    dtype: 'float16'
    # Autotuning the prefetch buffer size causes OOMs, so set it to a reasonable
    # static value: 32. See b/218880025.
    prefetch_buffer_size: 32
  validation_data:
    input_path: '/data/imagenet/tf_record/validation/validation*'
    is_training: false
    global_batch_size: 4096
    dtype: 'float16'
    drop_remainder: false
    prefetch_buffer_size: 32
trainer:
  train_steps: 3120
  validation_steps: -1 # val_imgs//batchsize
  validation_interval: 312
  steps_per_loop: 312
  summary_interval: 312
  checkpoint_interval: 1248
  optimizer_config:
    optimizer:
      type: 'lars'
      lars:
        momentum: 0.9
        weight_decay_rate: 0.00005
    learning_rate:
      type: 'polynomial'
      polynomial:
        initial_learning_rate: 13.35
        decay_steps: 10921
        end_learning_rate: 0.0001
        power: 2.0
        offset: 624
    warmup:
      type: 'linear'
      linear:
        warmup_steps: 624
        warmup_learning_rate: 0.0
